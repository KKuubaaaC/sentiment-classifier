{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 – Embeddingi\n",
        "\n",
        "Zamiana tekstów na wektory (sentence-transformers). Zapis embeddingów do pliku, żeby nie liczyć za każdym razem przy treningu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Ścieżka projektu i ładowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8c55206e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wczytano z data/processed/\n",
            "Train: 9577 | Val: 1002\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path.cwd()\n",
        "if not (root / \"src\").is_dir():\n",
        "    root = root.parent\n",
        "sys.path.insert(0, str(root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Opcja A: wczytaj z zapisanych CSV (po notatniku 02)\n",
        "processed_dir = root / \"data\" / \"processed\"\n",
        "train_path = processed_dir / \"train_clean.csv\"\n",
        "val_path = processed_dir / \"val_clean.csv\"\n",
        "\n",
        "if train_path.exists() and val_path.exists():\n",
        "    train_df = pd.read_csv(train_path, dtype={\"text_clean\": str})\n",
        "    val_df = pd.read_csv(val_path, dtype={\"text_clean\": str})\n",
        "    text_col = \"text_clean\"\n",
        "    print(\"Wczytano z data/processed/\")\n",
        "else:\n",
        "    # Opcja B: załaduj dataset i preprocess (jeśli nie uruchomiłeś 02)\n",
        "    from datasets import load_dataset\n",
        "    from src.preprocessing import PolishTextPreprocessor\n",
        "    dataset = load_dataset(\"allegro/klej-allegro-reviews\")\n",
        "    train_df = dataset[\"train\"].to_pandas()\n",
        "    val_df = dataset[\"validation\"].to_pandas()\n",
        "    preprocessor = PolishTextPreprocessor(remove_emoji=True, remove_stopwords=False)\n",
        "    train_df[\"text_clean\"] = preprocessor.preprocess_series(train_df[\"text\"])\n",
        "    val_df[\"text_clean\"] = preprocessor.preprocess_series(val_df[\"text\"])\n",
        "    text_col = \"text_clean\"\n",
        "    print(\"Wczytano dataset i wykonano preprocessing\")\n",
        "\n",
        "# Wymuszenie listy stringów (model.encode nie przyjmuje float/NaN)\n",
        "def to_string_list(ser):\n",
        "    out = []\n",
        "    for v in ser.values:\n",
        "        if isinstance(v, str):\n",
        "            out.append(v)\n",
        "        elif v is None or (isinstance(v, float) and np.isnan(v)):\n",
        "            out.append(\"\")\n",
        "        else:\n",
        "            out.append(str(v))\n",
        "    return out\n",
        "\n",
        "train_texts = to_string_list(train_df[text_col])\n",
        "val_texts = to_string_list(val_df[text_col])\n",
        "y_train = train_df[\"rating\"].values.astype(int)\n",
        "y_val = val_df[\"rating\"].values.astype(int)\n",
        "assert all(isinstance(t, str) for t in train_texts), \"train_texts zawiera nie-string\"\n",
        "assert all(isinstance(t, str) for t in val_texts), \"val_texts zawiera nie-string\"\n",
        "print(\"Train:\", len(train_texts), \"| Val:\", len(val_texts))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfcacb06",
      "metadata": {},
      "source": [
        "## 2. Model sentence-transformers i encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fca447ec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7c5aeff54754517b3960cc8df5f518c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: paraphrase-multilingual-MiniLM-L12-v2\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "print(\"Model:\", model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "239f998c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87e59fa30f8b457fa0738a544c1d4b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/150 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "065f37cef03c4b389cd56d6181faf999",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train: (9577, 384) | X_val: (1002, 384)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "X_train = model.encode(train_texts, batch_size=batch_size, show_progress_bar=True)\n",
        "X_val = model.encode(val_texts, batch_size=batch_size, show_progress_bar=True)\n",
        "print(\"X_train:\", X_train.shape, \"| X_val:\", X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Zapis embeddingów do data/processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zapisano X_train.npy, y_train.npy, X_val.npy, y_val.npy w data/processed/\n"
          ]
        }
      ],
      "source": [
        "processed_dir.mkdir(parents=True, exist_ok=True)\n",
        "np.save(processed_dir / \"X_train.npy\", X_train)\n",
        "np.save(processed_dir / \"y_train.npy\", y_train)\n",
        "np.save(processed_dir / \"X_val.npy\", X_val)\n",
        "np.save(processed_dir / \"y_val.npy\", y_val)\n",
        "print(\"Zapisano X_train.npy, y_train.npy, X_val.npy, y_val.npy w data/processed/\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
